# SeamFuzz-Artifact
This repository is for the implementation of our paper accepted in ICSE 2023, "Learning Seed-Adaptive Mutation Strategies for
Greybox Fuzzing".
Our tool, [SeamFuzz](https://github.com/kupl/SeamFuzz-public), is a grey-box mutation-based fuzzer built on [AFL++](https://github.com/AFLplusplus/AFLplusplus)-v3.15++.

# Requirements
Please refer [REQUIREMENTS.md](./REQUIREMENTS.md) for the operating system and hardware requirements.

# Setup
All experiments in our paper was done on [FuzzBench](https://github.com/google/fuzzbench) framework,
and therefore, the setup environments for our artifact is the same as the one for [FuzzBench](https://github.com/google/fuzzbench).
Please refer to the following [link](https://google.github.io/fuzzbench/) to establish the experimental environments.
You can also follow the instructions below to construct/evaluate SeamFuzz on FuzzBench.

We modified some parts of FuzzBench to evaluate some benchmark programs (objdump, infotocap, podofopdfinfo, magma_libxml2_xmllint) as follows:
```
fuzzbench
└── requirements.txt : modify some parts of the requirements.txt to make it work on > python3.9
└── experiment
|      └── measurer
|             └── run_coverage.py : "do_coverage_run" function is modified to properly evaluate some benchmark programs
└── fuzzers
|      └── afl
|      |    └── fuzzer.py         : "run_afl_fuzz" function is modified to properly evaluate some benchmark programs
       |
       └── aflpp : "build.Dockerfile" is modified to make the version of "AFL++" be the same as the one of SeamFuzz
       |
       └── aflppmopt : "build.Dockerfile" is modified to make the version of "AFL++" be the same as the one of SeamFuzz
```
If the users want to evaluate our fuzzers on the FuzzBench framework from original git, 
please modify the files above.
Otherwise, FuzzBench may not evaluate the benchmark programs.



### From Source
Following command will construct the experimental environments.  

```
cd ./fuzzbench && ./setup.sh
```


### VM(VirtualMachine) 
We also provide a VM image file which contain all contents to evaluate the experiments.
The VM image is built on [VirtualBox 7.0](https://www.virtualbox.org).
You can donwload the VM image from the following link.

# How to use
Once the setup is properly prepared (or using VM), enter the following command to reproduce the main evlauation results in our paper, which is Table 2 in Section IV.

## With Reproducing-Script Files

### Table 2 & Figure 3

```
./main_eval.sh -t [TRIALS] -s [TIME] -p [EXP_PATH] -r [REPORT] -e [EXP_NAME]
```

`main_eval.sh` will make a local experiment configuration file(`local-experiment-config.yaml`) for running FuzzBench on the local machine, running FuzzBench with all benchmark programs and fuzzers we used in our paper, and generate result table and venn-diagram for Table 2 and Figure 3.

The options for `main_eval.sh` is for generating a local experiment configuration file, and the option descriptions are as follows:

```
 [TRIALS]: the number of trials of the intended experiments. The default value is 20
 [TIME]: the seconds for the running experiments. The default value is 86400, which is 24 hours
 [EXP_PATH]: the path for storing the running data of FuzzBench. The default path is [the working directory]/data/
 [REPORT]: the path for storing the report of FuzzBench. The default path is [the working directory]/report/
 [EXP_NAME]: the name of the experiments which will be stored in [EXP_PATH]. The default name is maintable
```

Note that running FuzzBench requires lots of memory and storage. It may not work properly when running `main_eval.sh` script with the default settings. 
For example, running `main_eval.sh` without any additional options requires at least 840 (20 trials * 14 benchmarks * 3 fuzzers) CPU power. (The version we used FuzzBench assigns 1 CPU power to each experiment on a local machine)
If FuzzBench is eventually dead with `EOF` error, please set [TRIALS] option to a value less than 20 to reduce memory and storage usage. 

### Table N

```
./running_table[N].sh -t [TRIALS] -s [TIME] -p [EXP_PATH] -r [REPORT] -e [EXP_NAME]
```

`running_table[N].sh` will make a local experiment configuration file(`local-experiment-config.yaml`) for running FuzzBench on the local machine, running FuzzBench with the benchmark programs and fuzzers used in Table [N] in our paper, and generate result table for them.
For example, running_table3.sh will evaluate the experiments used to the Table 3 in our paper.

The options for `running_table[N].sh` is the same as the ones for `main_eval.sh`

### Result
After running each script file, `result` directory is produced in the current directory.
The details are as follows:

```
result
└── coverage.csv : contains average coverage of each fuzzer on each benchmark. (follows FuzzBench criteria)
|      
├── crashes.csv  : contains the number of crash inputs generated by each fuzzer on each benchmark (follows AFL++ criteria)
|      
├── result_table : contains a table which integrates coverage.csv and crashes.csv
|
└── unique_vul_venn_diagram.png : A Venn diagram for the unique vulnerabilities found by each tool (follows FuzzBench criteria)
```

## Without Reproducing-Script file 
You may want to run FuzzBench with your own flavors in usage.

```
./make_local_config.sh $TRIALS $TIME $EXP_PATH $REPORT
cp ./local-experiment-config.yaml ./fuzzbench/

PYTHONPATH=./fuzzbench/ \
python3.9 ./fuzzbench/experiment/run_experiment.py -cb [N] -a -c ./fuzzbench/local-experiment-config.yaml \
-b [BENCHMARKS] -f [FUZZERS] -e [EXP_NAME]
```

```
-cb [N]: cuncurrent building options. Higher the value, faster the building process. 
[BENCHMARKS] : give the full name of the the programs which will be used for experiments. The benchmark programs are in ./fuzzbench/benchmarks directory. ex) "-b arrow_parquet-arrow-fuzz grok_grk_decompress_fuzzer"
[FUZZERS] : give the full name of the fuzzers which will be used for experiments. The fuzzers are in ./fuzzbench/fuzzers directory. ex) "-f aflpp aflppmopt seamfuzz"
```

# Contact
Myungho Lee (e-mail: myungho_lee@korea.ac.kr)

